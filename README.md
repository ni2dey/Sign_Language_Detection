# Sign_Language_Detection
The Sign Language Detection model developed as minor project focused on real-time detection and interpretation of American sign language gestures. It uses Mediapipe and OpenCV for capturing hand landmarks and processing video inputs, while a Random Forest Classifier was employed to predict the corresponding signs based on the hand gestures. The model was integrated into a user-friendly GUI created with Tkinter, allowing users to input signs and see the predicted outputs in real time. This project aimed to facilitate communication for individuals using sign language.
